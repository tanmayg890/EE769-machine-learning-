{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2a747369b91572b4ada4e32643e31bca",
          "grade": false,
          "grade_id": "Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "V-8rdU6TmK76"
      },
      "source": [
        "#**EE769 Introduction to Machine Learning**\n",
        "\n",
        "#Assignment 1: Gradient Descent, Linear Regression, and Regularization\n",
        "\n",
        "\n",
        "**Template and Instructions**\n",
        "\n",
        "\n",
        "\n",
        "1. Up to two people can team up, but only one should submit, and both should understand the entire code.\n",
        "2. Every line of code should end in a comment explaining the line\n",
        "3. It is recommended to solve the assignment in Google Colab.\n",
        "Write your roll no.s separated by commas here: 17d070041, 18d070053\n",
        "4. Write your names here: Tanmay Goyal, Kirti Agarwal\n",
        "5. There are two parts to the assignment. In the Part 1, the code format has to be strictly followed to enable auto-grading. In the second part, you can be creative.\n",
        "6. **You can discuss with other groups or refer to the internet without being penalized, but you cannot copy their code and modify it. Write every line of code and comment on your own.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cae69541658b406d495bcffe0b7c0932",
          "grade": false,
          "grade_id": "cell-aa1aa8c8181f8810",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MDKB3K3AmK7-"
      },
      "source": [
        "#**Part 1 begins ...**\n",
        "**Instructions to be strictly followed:**\n",
        "\n",
        "1. Do not add any code cells or markdown cells until the end of this part. Especially, do not change the blocks that say \"TEST CASES, DO NOT CHANGE\"\n",
        "2. In all other cells only add code where it says \"CODE HERE\".\n",
        "3. If you encounter any raise NotImplementedError() calls you may comment them out.\n",
        "\n",
        "We cannot ensure correct grading if you change anything else, and you may be penalised for not following these instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0ecbf8e96219ab11b7716eaae61cb7f9",
          "grade": false,
          "grade_id": "cell-1e940101f37c7af2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "uDPguKC1mK7-"
      },
      "source": [
        "## Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe70877a859ee0a10e9d591778022f8a",
          "grade": false,
          "grade_id": "Import_Statements",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3obR0azgmK7_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e36a214573fc40f26b45e72215d61375",
          "grade": false,
          "grade_id": "Normalize_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "r6kfSJMdmK8A"
      },
      "source": [
        "## Normalize function \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "42293dda356d746ac19e9b6d81106261",
          "grade": false,
          "grade_id": "Normalize_Function",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "iozyv_ZbmK8A"
      },
      "outputs": [],
      "source": [
        "def Normalize(X): # Output should be a normalized data matrix of the same dimension\n",
        "  '''\n",
        "  Normalize all columns of X using mean and standard deviation\n",
        "  '''\n",
        "  # column wise (axis=0) mean of X\n",
        "  v_means = np.mean(X, axis=0) # 1-D array of column means\n",
        "  # column wise (axis=0) std_dev of X\n",
        "  v_std_dev = np.std(X, axis=0) # 1-D array of column standard deviations\n",
        "\n",
        "  # using numpy vectorized operations\n",
        "  X_norm = (X- v_means)/v_std_dev\n",
        "\n",
        "  return X_norm\n",
        "    # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7797dd606a68f028c945acd08850d108",
          "grade": true,
          "grade_id": "Normalize_Test",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rJMgNEEWmK8A"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - 1 dimensional array'''\n",
        "#X=np.array([[1,2,3],[3,4,5],[7,8,9]])\n",
        "X1=np.array([1,2,3])\n",
        "np.testing.assert_array_almost_equal(Normalize(X1),np.array([-1.224,  0.      ,  1.224]),decimal=3)\n",
        "''' case 2 - 2 dimensional array'''\n",
        "X2=np.array([[4,7,6],[3,8,9],[5,11,10]])\n",
        "np.testing.assert_array_almost_equal(Normalize(X2),np.array([[ 0.  , -0.980581, -1.372813],[-1.224745, -0.392232,  0.392232],[ 1.224745,  1.372813,  0.980581]]))\n",
        "''' case 3 - 1 dimensional array with float'''\n",
        "X3=np.array([5.5,6.7,3.2,6.7])\n",
        "np.testing.assert_array_almost_equal(Normalize(X3),np.array([-0.017,  0.822, -1.627,  0.822]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "63ee774a26a0438a0b2f5ec298eac80e",
          "grade": false,
          "grade_id": "cell-66ab98f84d3c58fa",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1tJtrJGhmK8B"
      },
      "source": [
        "## Prediction Function\n",
        "\n",
        "Given X and w, compute the predicted output. Do not forget to add 1's in X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5976e32bd96bc4bdc2b2efd61e98441c",
          "grade": false,
          "grade_id": "Prediction",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "FEij0nSzmK8B"
      },
      "outputs": [],
      "source": [
        "def Prediction (X, w): # Output should be a prediction vector y\n",
        "  '''\n",
        "  Compute Prediction given an input datamatrix X and weight vecor w. Output y = [X 1]w where 1 is a vector of all 1s \n",
        "  '''\n",
        "  # X_bias = [X 1]\n",
        "  # np.ones to construct a column matrix(N x 1) of ones, no of rows(N) = len(X)\n",
        "  # np.concatenate to join the column matrix to X along the rows (axis = 1)\n",
        "  X_bias = np.concatenate((X, np.ones((len(X), 1))), axis=1)\n",
        "\n",
        "  # matrix dot product [X 1].w\n",
        "  y = X_bias.dot(w) # (w acts as column vector)\n",
        "\n",
        "  return y\n",
        "    \n",
        "  # raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "741f088432fb2ac3c49d3c9711d5c9c5",
          "grade": true,
          "grade_id": "PredictionTest",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "EYM9Xeo4mK8C"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - Known input output matrix and weights 1'''\n",
        "X1 = np.array([[3,2],[1,1]])\n",
        "w1 = np.array([2,1,1]) \n",
        "np.testing.assert_array_equal(Prediction(X1,w1),np.array([9,4]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "227f6e0da2f8c6d631599c44041e3b65",
          "grade": false,
          "grade_id": "cell-6fda2832d5967072",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d5gGaidkmK8D"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "Code the four  loss functions:\n",
        "\n",
        "1. MSE loss is only for the error\n",
        "2. MAE loss is only for the error\n",
        "3. L2 loss is for MSE and L2 regularization, and can call MSE loss\n",
        "4. L1 loss is for MSE and L1 regularization, and can call MSE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2c3e17b8559f0dfdfecdc8d242aba152",
          "grade": false,
          "grade_id": "MSE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "He2_zmFWmK8D"
      },
      "outputs": [],
      "source": [
        "def MSE_Loss (X, t, w, lamda =0): # Ouput should be a single number\n",
        "  '''\n",
        "  lamda=0 is a default argument to prevent errors if you pass lamda to a function that doesn't need it by mistake. \n",
        "  This allows us to call all loss functions with the same input format.\n",
        "  \n",
        "  You are encouraged read about default arguments by yourself online if you're not familiar.\n",
        "  '''\n",
        "  # call Prediction and store predictions in y\n",
        "  y= Prediction(X,w)\n",
        "  # calclulate error vector\n",
        "  err = t-y\n",
        "  # calc mean of err**2 (squared error)\n",
        "  MSE = np.mean(err**2)\n",
        "  return MSE\n",
        "\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "923a1372a401b41d6ef6b0749a49ff66",
          "grade": true,
          "grade_id": "MSE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DcvgbrzcmK8E"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MSE_Loss(X,t,w),0.53,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b0b3b381c7a3ac5d7dfbb5df647c0d85",
          "grade": false,
          "grade_id": "MAE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "6iRIUptemK8E"
      },
      "outputs": [],
      "source": [
        "def MAE_Loss (X, t, w, lamda = 0): # Output should be a single number\n",
        "  # call Prediction and store predictions in y\n",
        "  y= Prediction(X,w)\n",
        "  # calclulate error vector\n",
        "  err = t-y\n",
        "  # mean of absolute values of errors\n",
        "  MAE = np.mean(np.absolute(err))\n",
        "  return MAE\n",
        "    # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f11d5fde7220893a9809f2954d18c5e5",
          "grade": true,
          "grade_id": "MAE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "tve6LCc9mK8E"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MAE_Loss(X,t,w),0.700,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8309762ea56bb6b24bbbf4a19cb16bc",
          "grade": false,
          "grade_id": "L2_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qoWj2b5_mK8E"
      },
      "outputs": [],
      "source": [
        "def L2_Loss (X, t, w, lamda): # Output should be a single number based on L2-norm (with sqrt)\n",
        "  ''' Need to specify what inputs are'''\n",
        "  # L2_Loss = MSE + lamda * (L2_norm of w[:-1](slicing to exclude bias term))\n",
        "  # np.linalg.norm calculates L2_norm by default for vectors\n",
        "  MSE_L2 = MSE_Loss(X,t,w) + lamda*np.linalg.norm(w[:-1])\n",
        "  return MSE_L2\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5a409056f6797cdf8cbfab61b138c37",
          "grade": true,
          "grade_id": "L2_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FYi_q2GJmK8F"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L2_Loss(X,t,w,0.5),1.675,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1af69c123815524cdc71c72e09ece638",
          "grade": false,
          "grade_id": "L1_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YvUKBlxjmK8F"
      },
      "outputs": [],
      "source": [
        "def L1_Loss (X, t, w, lamda): # Output should be a single number\n",
        "  # L1_Loss = MSE + lamda * (L1_norm of w[:-1](slicing to exclude bias term))\n",
        "  MSE_L1 = MSE_Loss(X,t,w) + lamda*np.linalg.norm(w[:-1], ord=1)\n",
        "  return MSE_L1\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40224dd69dd8e6499a67271c33701bf4",
          "grade": true,
          "grade_id": "L1_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rRZxPKwemK8F"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L1_Loss(X,t,w,0.5),2.280,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "855bd2ded492e567b20f1d9705d9a97a",
          "grade": false,
          "grade_id": "NRMSE_Metric",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "TJ33VUvemK8F"
      },
      "outputs": [],
      "source": [
        "def NRMSE_Metric (X, t, w, lamda=0): # Output should be a single number. RMSE/std_dev(t)\n",
        "  # Calc standard deviation of t\n",
        "  t_std_dev = np.std(t)\n",
        "  # Calc RMSE = sqrt(MSE)\n",
        "  RMSE = np.sqrt(MSE_Loss(X,t,w))\n",
        "  # Calc NRMSE = RMSE/(standard deviation of t)\n",
        "  NRMSE = RMSE/t_std_dev\n",
        "\n",
        "  return NRMSE\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "256795799ceb6dfa0b32ab75e8ef30c4",
          "grade": true,
          "grade_id": "NRMSE_Metric_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WE2p1bptmK8F"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' Test case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(NRMSE_Metric(X,t,w,0.5),0.970,decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "cc5df30e29bbe17d4bc7aa89210eb5cf",
          "grade": false,
          "grade_id": "Gradient_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UPdKyXoNmK8F"
      },
      "source": [
        "## Gradient function\n",
        "Each Loss function will have its own gradient function:\n",
        "\n",
        "1. MSE gradient is only for the error\n",
        "2. MAE gradient is only for the error\n",
        "3. L2 gradient is for MSE and L2 regularization, and can call MSE gradient\n",
        "4. L1 gradient is for MSE and L1 regularization, and can call MSE gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0190492ee216edce701f93e697572fc1",
          "grade": false,
          "grade_id": "MSE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Yaqd-wFomK8G"
      },
      "outputs": [],
      "source": [
        "def MSE_Gradient (X, t, w, lamda=0): # Output should have the same size as w\n",
        "  # Calc X_bias = [X 1] for calculations\n",
        "  X_bias = np.concatenate((X, np.ones((len(X), 1))), axis=1)\n",
        "  # MSE_grad = (2/len(X))*(w.X_bias'.X_bias - t.X_bias)\n",
        "  # (t,w act as Row vector)\n",
        "  MSE_grad = (2/len(X))*(w.dot(X_bias.transpose().dot(X_bias)) - t.dot(X_bias))\n",
        "  return MSE_grad\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d61466927592a8776a8bfa688472bad4",
          "grade": true,
          "grade_id": "MSE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "t--RfDXumK8G"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MSE_Gradient(X,t,w),np.array([2.55, 2.94, 2.9 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "49cc4e37cafad52f41853b4b0e71f89f",
          "grade": false,
          "grade_id": "MAE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "A6fUTdoLmK8G"
      },
      "outputs": [],
      "source": [
        "def MAE_Gradient (X, t, w, lamda=0): # Output should have the same size as w\n",
        "  # Call Prediction() and store predictions in y\n",
        "  y = Prediction(X,w)\n",
        "  # Calc error vector\n",
        "  err = t - y\n",
        "  # Compute X_bias = [X 1] for calculations\n",
        "  X_bias = np.concatenate((X, np.ones((len(X), 1))), axis=1)\n",
        "  # MAE_grad[i] = signum(err).(-X[:,i])/len(X) \n",
        "  # MAE_grad = -signum(err).X_bias/len(X); (err act as row vector)\n",
        "  MAE_grad = -np.sign(err).dot(X_bias)/len(X)\n",
        "  return MAE_grad\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d418bf5351112ae8716877f8bb6359",
          "grade": true,
          "grade_id": "MAE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "x70FZSfemK8G"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MAE_Gradient(X,t,w),np.array([0.75,  0.3 ,  0.5 , 0.]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "595829c0dd17df55a03d346fac507b4a",
          "grade": false,
          "grade_id": "L2_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "sih6A1IImK8G"
      },
      "outputs": [],
      "source": [
        "def L2_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "  # store MSE_Gradient in MSE_grad\n",
        "  MSE_grad = MSE_Gradient(X,t,w)\n",
        "  # Calc L2_regulizer gradient = lamda*(1/L2_norm(w[:-1]))*np.append(w[:-1],0)\n",
        "  # np.append(w[:-1],0) since L2_norm gradient wrt bias weight is zero\n",
        "  L2_reg_grad = (lamda/np.linalg.norm(w[:-1]))*np.append(w[:-1], 0)\n",
        "  # calc L2_gradient = MSE_grad + L2_reg_grad\n",
        "  L2_grad = MSE_grad + L2_reg_grad\n",
        "  return L2_grad\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f292b42c3389b24e369234a7210b87bb",
          "grade": true,
          "grade_id": "L2_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "yv7rChsfmK8G"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L2_Gradient(X,t,w,0.5),np.array([2.986, 2.721, 3.009 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "141736f1feda5aa225e008d749f0015c",
          "grade": false,
          "grade_id": "L1_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1nkOYNPpmK8H"
      },
      "outputs": [],
      "source": [
        "def L1_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "  # store MSE_Gradient in MSE_grad\n",
        "  MSE_grad = MSE_Gradient(X,t,w)\n",
        "  # Calc L1_regulizer gradient = lamda* sign(np.append(w[:-1],0))\n",
        "  # np.append(w[:-1],0) since L1_norm gradient wrt bias weight is zero\n",
        "  L1_reg_grad = lamda*np.sign(np.append(w[:-1], 0))\n",
        "  # calc L1_gradient = MSE_grad + L1_reg_grad\n",
        "  L1_grad = MSE_grad + L1_reg_grad\n",
        "  return L1_grad\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9097b61320e470f429a9f46c7da0b219",
          "grade": true,
          "grade_id": "L1_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fNrXkyLYmK8H"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L1_Gradient(X,t,w,0.5),np.array([3.05, 2.44, 3.4 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1980a2f831b5e1ddc9b510c22ef502c7",
          "grade": false,
          "grade_id": "Gradient_Desc_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "KnXOY_0EmK8H"
      },
      "source": [
        "## Gradient Descent Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "78cdd5ffa4590c10e19281722ccd537f",
          "grade": false,
          "grade_id": "Gradient_Descent",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "uWIR-s1WmK8H"
      },
      "outputs": [],
      "source": [
        "def Gradient_Descent (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement\n",
        "  # initialize count -> no of iterations as 0\n",
        "  # delta -> current loss - loss after one step\n",
        "  # initialize delta as anything>=epsilon for first iteration\n",
        "  count, delta = 0, epsilon\n",
        "  # w_pre -> current weight vector\n",
        "  # w_post -> weight vector after one step\n",
        "  # initialize w_pre with given weight vector w\n",
        "  w_pre = w\n",
        "  # calc loss_pre for w_pre\n",
        "  loss_pre = lossfunc(X, t, w_pre, lamda)\n",
        "  # start the while loop for further iterations of gradient descent\n",
        "  # loop breaks if count exceeds max_iter\n",
        "  # or delta is less than epsilon\n",
        "  while (count <= max_iter) and  (delta >= epsilon):\n",
        "    # perform one step of gradient descent\n",
        "    # w_post = w_pre - learning_rate * (gradient at w_pre)\n",
        "    w_post = w_pre - lr*gradfunc(X, t, w_pre, lamda)\n",
        "    # calc loss_post as loss for w_post\n",
        "    loss_post = lossfunc(X, t, w_post, lamda)\n",
        "    # update delta as loss_pre - loss_post\n",
        "    delta = abs(loss_pre - loss_post)\n",
        "    # update variables for next iteration\n",
        "    # w_post will now be w_pre\n",
        "    w_pre = w_post\n",
        "    # loss_post will now be loss_pre\n",
        "    loss_pre = loss_post\n",
        "    # increment no of iterations by 1\n",
        "    count += 1\n",
        "  \n",
        "\n",
        "  # w_pre now holds the final weight vector\n",
        "  # assign w_pre to w_final\n",
        "  w_final = w_pre\n",
        "  # Calculate training loss with w_final\n",
        "  train_loss_final = lossfunc(X, t, w_final, lamda)\n",
        "  # Calculate validation loss with w_final\n",
        "  validation_loss_final = lossfunc(X_val, t_val, w_final, lamda)\n",
        "  # Calculate validation NRMSE with w_final\n",
        "  validation_NRMSE = NRMSE_Metric(X_val, t_val, w_final)\n",
        "    \n",
        "  return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this.\n",
        "  # raise NotImplementedError() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "15a67336bed20a51f33820bf615186e8",
          "grade": true,
          "grade_id": "Gradient_Check",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ZO0r2j4GmK8H"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "X=np.array([[23,24],[1,2]])\n",
        "t=np.array([4,5])\n",
        "X_val=np.array([[3,4],[5,6]])\n",
        "t_val=np.array([3,4])\n",
        "w=np.array([3,2,1])\n",
        "results =Gradient_Descent (X, X_val, t, t_val, w, 0.1, 100, 1e-10, 1e-5, L2_Loss,L2_Gradient) \n",
        "np.testing.assert_allclose([results[1]],[697.919],rtol =0.05)\n",
        "np.testing.assert_allclose([results[2]],[20],atol=5) # we expect around 17.5  but some students got 24 which we will also accept\n",
        "#Instructor Values of results[1] and results [2] are 697.919 and 17.512 respectively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "24f327aa6a14590077f907ee8323724c",
          "grade": false,
          "grade_id": "PseudoInvTitle",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BVVUIYRImK8H"
      },
      "source": [
        "## Pseudo Inverse Method\n",
        "\n",
        "You have to implement a slightly more advanced version, with L2 penalty:\n",
        "\n",
        "w = (X' X + lambda I)^(-1) X' t.\n",
        "\n",
        "See, for example: Section 2 of https://web.mit.edu/zoya/www/linearRegression.pdf\n",
        "\n",
        "Here, the column of 1's in assumed to be included in X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "928c9b105c4bcf3c132c7520a140d509",
          "grade": false,
          "grade_id": "PseudoInv",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "JdPbK8yCmK8H"
      },
      "outputs": [],
      "source": [
        "def Pseudo_Inverse (X, t, lamda): # Output should be weight vector\n",
        "  # compute X_bias = [X 1] for calculations\n",
        "  X_bias = np.concatenate((X, np.ones((len(X), 1))), axis=1)\n",
        "  # compute transpose of X_bias\n",
        "  X_biasT = X_bias.transpose()\n",
        "  # compute lamda * I, I -> Identity matrix of order X_bias.shape[1]\n",
        "  # since X_biasT.X_bias is a square matrix with order X_bias.shape[1]\n",
        "  lamda_I = lamda*np.eye(X_bias.shape[1])\n",
        "  # Calculate pseudo_inv with L2 penalty as (X_biasT.X_bias + lamda*I)^(-1).X_biasT\n",
        "  pseudo_inv_L2 = np.linalg.inv(X_biasT.dot(X_bias) + lamda_I).dot(X_biasT)\n",
        "  # calculate w as pseudo_inv_L2.t\n",
        "  # (t acts as a column vector here)\n",
        "  w = pseudo_inv_L2.dot(t)\n",
        "  \n",
        "  return w\n",
        "  # raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5178b8280650ed5d1d55dc6bbb38a29",
          "grade": true,
          "grade_id": "PseudoInvTest",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FyMYFIAjmK8H"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - other data'''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "np.testing.assert_array_almost_equal(Pseudo_Inverse(X,t,0.5),np.array([ 0.491,  0.183,  0.319, -0.002]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8748fcc0dc96df6e7bb48a4e315927d3",
          "grade": false,
          "grade_id": "cell-e0fa02d7eecfb851",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "89eVtrJJmK8I"
      },
      "source": [
        "#... Part 1 ends Below this you be more creative. Just comment out the lines where you save files (e.g. test predictions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c9047f75587bfee6b7b0a4b244efc7fa",
          "grade": false,
          "grade_id": "cell-10f0d275f5cd36f6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SG3arlRFmK8I"
      },
      "source": [
        "#**Part 2 begins ...**\n",
        "\n",
        "**Instructions to be loosely followed (except number 8):**\n",
        "\n",
        "1. Add more code and text cells between this and the last cell.\n",
        "2. Read training data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv only. Do not use a local copy of the dataset.\n",
        "3. Find the best lamda for **MSE+lamda*L2(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.\n",
        "4. Find the best lamda for **MSE+lamda*L1(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.\n",
        "5. Find the best lamda for the **pseudo-inv method**. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NRMSE for the best lamda.\n",
        "6. Write your observations and conclusions.\n",
        "7. Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NRMSE. Save it as a file RollNo1_RollNo2_1.csv.\n",
        "8. **Disable the prediction csv file saving statement and submit this entire .ipynb file, .py file, and .csv file as a single RollNo1_RollNo2_1.zip file.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Reading and pre-processing"
      ],
      "metadata": {
        "id": "lx-9YTzflI2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read training data from the given link\n",
        "df_train = pd.read_csv(\"https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv\")"
      ],
      "metadata": {
        "id": "5vCBrOti-1st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate the independent variables [first 17 columns]\n",
        "# and the target (dependent) variable [last column]\n",
        "x = np.array(df_train.iloc[:,:-1])\n",
        "t = np.array(df_train.iloc[:,-1])\n",
        "\n",
        "# normalize the data matrix of independent variables\n",
        "x_norm = Normalize(x)"
      ],
      "metadata": {
        "id": "NZWOMiXD-1pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 85-15 split for training-validation\n",
        "# for np.split(), 2nd argument is a list of points\n",
        "# at which the split has to be done, we only need one split\n",
        "# int(0.85*len(x_raw)) refers to the row index roughly 85% of the total no. of rows\n",
        "x_train, x_val = np.split(x_norm, [int(0.85*len(x))])\n",
        "t_train, t_val = np.split(t, [int(0.85*len(x))])"
      ],
      "metadata": {
        "id": "zUcDrXdT-1mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Now we have separate training(x_train, t_train) and validation(x_val, t_val) dataset.\n",
        "* Proceed ahead for training and validation to find the best set of parameters w. "
      ],
      "metadata": {
        "id": "WGCUz8OmlnLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation\n",
        "\n",
        "---\n",
        "\n",
        "Goal : To find an optimum weight vector (model) with least validation RMSE.\n",
        "\n",
        "Process : \n",
        "\n",
        "*   To train the Linear regression model for L2 and L1 regularized loss functions.\n",
        "*   Optimization (Parameter Tuning) problem boiled down to minimizing the loss functions. We use Gradient descent algorithm for minimization.\n",
        "*   Then we tune the hyperparameter lamda by literally putting to test the optimum w obtained from various lamda against the validation data and plotting the RMSE vs 1/lamda curve. \n",
        "*   For both  L1 and L2 loss, we obtain the best lamda and thus corresponding optimum solutions for the weight vector, i.e. the model parameters.\n",
        "*   Then we use the pseudo inverse method, i.e., the analytical solution for minima of L2 loss functions with respect to w. This is in contrast to using the gradient descent algorithm for finding the minima.\n",
        "* Again we tune the hyperparameter lamda to obtain the best performing model.\n",
        "* Now out of all the 3 optimal model choices, we choose the model with best validation RMSE and make predictions given the test data.\n",
        "* These are then saved into a csv file."
      ],
      "metadata": {
        "id": "1St5BGPta4Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal model parameters using ***L2 Loss***\n",
        "---\n",
        "\n",
        "\n",
        "* Optimization problem -> ***minimize the loss function.***\n",
        "* Optimization algorithm -> ***Gradient Descent***"
      ],
      "metadata": {
        "id": "K55tzl25nJZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up **Gradient Descent** (**max_iter, epsilon and lr**)\n",
        "* Follwing we perform an experiment to fix upon the stopping criteria, max no. of iterations and learning rate.\n",
        "* **Rough Design** : \n",
        "* Three values of lamda, 0, 0.5 and 1 will be used to finalize the parameters.\n",
        "* Start with conducting the experiment for lamda = 0, take max_iter = 1000 and epsilon = 1e-5 to start with\n",
        "* vary the learning rate, epsilon, max_iter to obtain a nicely performing gradient descent optimizer.\n",
        "* Repeat the same for lamda =1, then lamda = 0.5\n",
        "* Validate that the final parameter choices work well for all three values of lamda"
      ],
      "metadata": {
        "id": "hECBMnb9wexz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modify the original Gradient Descent function\n",
        "Making a slightly modified copy of the original gradient descent function for better analysis.\n",
        "* Validation data is removed form input\n",
        "* Output is modified to print number of iterations, absolute change in loss in the last iteration and the final training loss."
      ],
      "metadata": {
        "id": "MqdqPlfEYavJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Gradient_Descent_modified (X, t, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement\n",
        "  # input/output modified\n",
        "  # rest same as original grad descent function\n",
        "  # for comments and description refer to original grad descent\n",
        "  # implementation in part 1\n",
        "\n",
        "  count, delta = 0, epsilon\n",
        "  w_pre = w\n",
        "  loss_pre = lossfunc(X, t, w_pre, lamda)\n",
        "\n",
        "  while (count <= max_iter) and  (delta >= epsilon):\n",
        "    w_post = w_pre - lr*gradfunc(X, t, w_pre, lamda)\n",
        "    loss_post = lossfunc(X, t, w_post, lamda)\n",
        "    delta = abs(loss_pre - loss_post)\n",
        "    w_pre = w_post\n",
        "    loss_pre = loss_post\n",
        "    count += 1\n",
        "  \n",
        "  w_final = w_pre\n",
        "  train_loss_final = loss_post\n",
        "  # print delta, count and final loss\n",
        "  print('count = ', count-1)\n",
        "  print('delta = ', delta)\n",
        "  print('minimum loss = ', loss_post,'\\n')\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "MMRKGdCNxACQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments for Gradient Descent for L2 Loss"
      ],
      "metadata": {
        "id": "Okydr_hnq4eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize w as w_init\n",
        "# from uniform distribution over [0,1) \n",
        "w_init = np.random.rand(x.shape[1]+1)"
      ],
      "metadata": {
        "id": "ikQcGgYFb83T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_arr = [0.05, 0.1, 0.13, 0.15, 0.17, 0.19, 0.22]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 0, 1000, 1e-5, lr, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3-C0BwL-1kF",
        "outputId": "cf9f19c7-5506-4801-8801-9d2750f8636f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  417\n",
            "delta =  9.979740802412707e-06\n",
            "minimum loss =  1.9559830424629316 \n",
            "\n",
            "count =  236\n",
            "delta =  9.837796150380385e-06\n",
            "minimum loss =  1.9555763144439489 \n",
            "\n",
            "count =  189\n",
            "delta =  9.9133075728286e-06\n",
            "minimum loss =  1.9554868104001957 \n",
            "\n",
            "count =  168\n",
            "delta =  9.689812418223198e-06\n",
            "minimum loss =  1.955439763442426 \n",
            "\n",
            "count =  151\n",
            "delta =  9.678936210288924e-06\n",
            "minimum loss =  1.955408706243508 \n",
            "\n",
            "count =  137\n",
            "delta =  9.797114103315963e-06\n",
            "minimum loss =  1.9553868344510497 \n",
            "\n",
            "count =  1000\n",
            "delta =  5.93538096426019e+115\n",
            "minimum loss =  2.5450451973919326e+116 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observing the trend in the minimum loss functions, safe choice for learning rate seems to be 0.17.\n",
        "\n",
        "Now we will decrease epsilon to improve the descent even further"
      ],
      "metadata": {
        "id": "J0RVDDXde9TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# learning rate = 0.19\n",
        "eps_arr = [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
        "for eps in eps_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 0, 1000, eps, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbFAwR0ze5og",
        "outputId": "cdb095fe-b836-4792-ceb4-0c58b345b46e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  151\n",
            "delta =  9.678936210288924e-06\n",
            "minimum loss =  1.955408706243508 \n",
            "\n",
            "count =  205\n",
            "delta =  9.89249670402259e-07\n",
            "minimum loss =  1.9552074217644515 \n",
            "\n",
            "count =  260\n",
            "delta =  9.724915939202106e-08\n",
            "minimum loss =  1.9551867162204886 \n",
            "\n",
            "count =  314\n",
            "delta =  9.974524317613032e-09\n",
            "minimum loss =  1.9551846900252234 \n",
            "\n",
            "count =  369\n",
            "delta =  9.808269751943044e-10\n",
            "minimum loss =  1.9551844812221475 \n",
            "\n",
            "count =  424\n",
            "delta =  9.644773868444645e-11\n",
            "minimum loss =  1.955184460689861 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apparently, there is no significant improvement in performance for lower values of epsilon and considering the increase in number of iterations for lower epsilon, \n",
        "a good and safe choice can be 1e-8"
      ],
      "metadata": {
        "id": "NdqSVh5wf2Ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, max_iter = 1000, epsilon = 1e-8, learning rate = 0.17. Now we test and tweak this for lamda = 1"
      ],
      "metadata": {
        "id": "cqAXwT8Mgu7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gradient_Descent_modified (x_train, t_train, w_init, 1, 1000, 1e-8, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OI7Cafd-xj1E",
        "outputId": "2b4e320b-50dc-4382-8584-ca7fc8c03247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  51\n",
            "delta =  7.926496792265425e-09\n",
            "minimum loss =  3.5977930000677656 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try for a variety of learning rates\n",
        "lr_arr = [0.25, 0.22, 0.19, 0.17, 0.15, 0.1, 0.05, 0.01]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 1, 1000, 1e-8, lr, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w523-cFRiSsJ",
        "outputId": "a5233b19-ea69-4ca4-c074-ca5c32941383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  970\n",
            "delta =  nan\n",
            "minimum loss =  inf \n",
            "\n",
            "count =  1000\n",
            "delta =  1.5717758817721808e+116\n",
            "minimum loss =  6.739652742373488e+116 \n",
            "\n",
            "count =  167\n",
            "delta =  9.487476582137333e-09\n",
            "minimum loss =  3.597793064304 \n",
            "\n",
            "count =  51\n",
            "delta =  7.926496792265425e-09\n",
            "minimum loss =  3.5977930000677656 \n",
            "\n",
            "count =  58\n",
            "delta =  7.65713270567403e-09\n",
            "minimum loss =  3.597793002594001 \n",
            "\n",
            "count =  86\n",
            "delta =  9.311230897424139e-09\n",
            "minimum loss =  3.5977930228761554 \n",
            "\n",
            "count =  169\n",
            "delta =  9.05446517762698e-09\n",
            "minimum loss =  3.5977930678073164 \n",
            "\n",
            "count =  773\n",
            "delta =  9.97921034695537e-09\n",
            "minimum loss =  3.59779347732478 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation : Observe the final minimum loss. Increasing the learning rate decreases the performance, while decreasing the learning rate doesn't cause any significant change in the performance. "
      ],
      "metadata": {
        "id": "BijvsXPTyGPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Let's see if there is any improvement if we increase number of iterations to 5000"
      ],
      "metadata": {
        "id": "T7wNM2jo0o2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# increase max_iter to 5000\n",
        "lr_arr = [0.22, 0.19, 0.17, 0.15, 0.1, 0.05, 0.01]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 1, 5000, 1e-8, lr, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8vIKzjJk_NQ",
        "outputId": "08ae7c85-40eb-4465-9239-60e86335dabb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:160: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  2629\n",
            "delta =  nan\n",
            "minimum loss =  inf \n",
            "\n",
            "count =  167\n",
            "delta =  9.487476582137333e-09\n",
            "minimum loss =  3.597793064304 \n",
            "\n",
            "count =  51\n",
            "delta =  7.926496792265425e-09\n",
            "minimum loss =  3.5977930000677656 \n",
            "\n",
            "count =  58\n",
            "delta =  7.65713270567403e-09\n",
            "minimum loss =  3.597793002594001 \n",
            "\n",
            "count =  86\n",
            "delta =  9.311230897424139e-09\n",
            "minimum loss =  3.5977930228761554 \n",
            "\n",
            "count =  169\n",
            "delta =  9.05446517762698e-09\n",
            "minimum loss =  3.5977930678073164 \n",
            "\n",
            "count =  773\n",
            "delta =  9.97921034695537e-09\n",
            "minimum loss =  3.59779347732478 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no improvement by increasing the max_iter to 5000 for any learning rate. Clearly, our choice for learning rate = 0.17 works very well for lamda=1.\n",
        " \n",
        "Let's try a lower value of max_iter, say 500. Maybe we can make do with lower value of max_iter, this will make training faster"
      ],
      "metadata": {
        "id": "JREQ7QnjlKIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max_iter = 500\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 1, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn9xcGxT4p_b",
        "outputId": "0bc87901-869c-4c72-e6e2-202d8c7df336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  51\n",
            "delta =  7.926496792265425e-09\n",
            "minimum loss =  3.5977930000677656 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no significant depreciation in performance. So lets fix on max_iter=500, epsilon= 1e-8, and lr= 0.17\n",
        "\n",
        "Let's validate this new setting for lamda=0"
      ],
      "metadata": {
        "id": "I8c-Q_pw1ZNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gradient_Descent_modified (x_train, t_train, w_init, 0, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBqIgTUw13uY",
        "outputId": "f3b0b5a4-9c05-45cb-cd32-e7605d4e3d91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  319\n",
            "delta =  9.840431136609595e-09\n",
            "minimum loss =  1.955184686912187 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works as the minimum loss is almost same as best obtained before. Now as the final step, let's validate our parameters by repeating the above experiment for a middle value of lamda say lamda = 0.5"
      ],
      "metadata": {
        "id": "pCPOtSRE19Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the same for lamda = 0.5\n",
        "lr_arr = [0.22, 0.19, 0.17, 0.15, 0.1, 0.05, 0.01]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 1000, 1e-8, lr, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Mt5DJjj8gK",
        "outputId": "61d608b2-23b2-424f-8103-02b8e413d7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  8.852450190821168e+115\n",
            "minimum loss =  3.795861795386697e+116 \n",
            "\n",
            "count =  88\n",
            "delta =  8.812418794690302e-09\n",
            "minimum loss =  2.8758435174433457 \n",
            "\n",
            "count =  91\n",
            "delta =  9.093730213294293e-09\n",
            "minimum loss =  2.875843533822543 \n",
            "\n",
            "count =  102\n",
            "delta =  9.98255522688396e-09\n",
            "minimum loss =  2.875843548375216 \n",
            "\n",
            "count =  151\n",
            "delta =  9.269195633265781e-09\n",
            "minimum loss =  2.8758435792376886 \n",
            "\n",
            "count =  288\n",
            "delta =  9.83553016808969e-09\n",
            "minimum loss =  2.875843698549965 \n",
            "\n",
            "count =  1000\n",
            "delta =  1.2331211518556984e-07\n",
            "minimum loss =  2.8758564714424883 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_iter = 5000\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 5000, 1e-8, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQYoQjxgl_9W",
        "outputId": "c0d43ecb-d336-43bd-a7e6-700d0d078797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  91\n",
            "delta =  9.093730213294293e-09\n",
            "minimum loss =  2.875843533822543 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_iter = 500\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYNsbcCLLeyP",
        "outputId": "6a3d8487-2e39-425b-da69-50751fc0413a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  91\n",
            "delta =  9.093730213294293e-09\n",
            "minimum loss =  2.875843533822543 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation** : \n",
        "* Clearly, our parameter choices work well enough for lamda = 0.5 as well. We tried searching for better parameters for this lamda, but as it turns out, our initial choice works just fine.\n",
        "\n"
      ],
      "metadata": {
        "id": "TWwvQ-aGjnAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final Gradient Descent Parameters** \n",
        "\n",
        "So the final choices are as follows:\n",
        "* Learning Rate (lr)  = 0.17\n",
        "* Maximum iterations (max_iter) = 500\n",
        "* Epsilon =  1e-8"
      ],
      "metadata": {
        "id": "5Gv7kWroxDa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hyperparameter Tuning***\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* Plotting Validation RMSE vs 1/lamda\n",
        "* Intial range of 1/lamda : 1 to 1000, 100 values"
      ],
      "metadata": {
        "id": "VpD4oVn7xbbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## This cell takes around 30-40s to execute\n",
        "\n",
        "# Here on, we use the original gradient descent function.\n",
        "# define initial range for 1/lamda from 1 to 1000\n",
        "# and observe the validation rmse plot.\n",
        "lamda_inv = np.linspace(1, 1000, 100)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  w_init = np.random.rand(x.shape[1]+1)\n",
        "  # run gradient descent and store resulting w in w_op (w optimal)\n",
        "  w_op = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, 1/l_inv, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)[0]\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "c7lBIxIe-1eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Train_RMSE)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ql1x3LGNx_so",
        "outputId": "b79a53e3-8ce0-4f15-e5fd-4bc894ff4e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nZo5iIrAx_pJ",
        "outputId": "c8444f26-a530-4dd1-b7f2-ea28a1ddee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe a clear minima. Let's go ahead, calculate the same and store it for future reference."
      ],
      "metadata": {
        "id": "1Y8OvcBeWlzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv_min = lamda_inv[np.argmin(Val_RMSE)]\n",
        "val_rmse_min = np.min(Val_RMSE)\n",
        "print('1/lamda at minima = ', lamda_inv_min)\n",
        "print('Minimum Validation RMSE = ', val_rmse_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrF_JFFY8A1s",
        "outputId": "685c2e9c-2399-4ff3-8c5f-26fffdf464ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/lamda at minima =  11.090909090909092\n",
            "Minimum Validation RMSE =  1.4868970623899997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now although we have got a clear minima, just to be on the safe side, and ensure that it is indeed a global minima, let's observe the validation rmse curve for a very wide range of 1/lamda.\n",
        "\n",
        "Let's choose the range as 100 to 1e+8"
      ],
      "metadata": {
        "id": "s40MWZtF8zFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(100, 1e+8, 50)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  w_init = np.random.rand(x.shape[1]+1)\n",
        "  # run gradient descent and store resulting w in w_op (w optimal)\n",
        "  w_op = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, 1/l_inv, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)[0]\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  # Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "rSMw6aY9R_s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "0M4SgSv9SLkt",
        "outputId": "6a1b03a2-8a90-4bb3-d19d-f3884863d4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, we had observed a global minima in the previous step."
      ],
      "metadata": {
        "id": "ARfwlCNJ9-au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion**\n",
        "\n",
        "Thus best lambda for **L2 Loss** is approximately 1/11.091 = 0.09\n",
        "with validation rmse alround 1.487\n"
      ],
      "metadata": {
        "id": "YGwH0MFaGFs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the optimum weight vector for L2_Loss\n",
        "lamda_best_L2 = 1/lamda_inv_min\n",
        "w_best_L2 = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, lamda_best_L2, 500, 1e-8, 0.17, L2_Loss, L2_Gradient)[0]\n",
        "best_val_RMSE_L2 = np.sqrt(MSE_Loss(x_val, t_val, w_best_L2))\n",
        "best_val_NRMSE_L2 = NRMSE_Metric(x_val, t_val, w_best_L2)\n",
        "print('optimum w :\\n', w_best_L2)\n",
        "print('\\nValidation RMSE : ', best_val_RMSE_L2)\n",
        "print('Validation NRMSE : ', best_val_NRMSE_L2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgV0n8sC2kOh",
        "outputId": "16348d44-9be3-485c-f353-4d30a3e525a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimum w :\n",
            " [ 4.29033189e-01  9.04722365e-02  3.24134149e-01 -1.16341297e-01\n",
            "  1.76576738e+00  3.09033646e-01 -3.69301909e-01  2.73989734e-01\n",
            " -4.07237641e-01 -1.40847661e-01 -1.71715910e-01 -2.84663483e-01\n",
            " -7.87267597e-02  1.98171486e-01 -2.07006498e-02  1.40551803e-02\n",
            " -6.45385099e-02 -1.14324806e-01 -2.16901519e-01  2.71089441e-01\n",
            "  1.25517729e-01  3.02231732e+01]\n",
            "\n",
            "Validation RMSE :  1.4868967181750952\n",
            "Validation NRMSE :  0.3951728816170014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimal model parameters using **L1 Loss**\n",
        "* Optimization problem -> ***minimize the loss function.***\n",
        "* Optimization algorithm -> ***Gradient Descent***"
      ],
      "metadata": {
        "id": "2AZia-kuyFER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up **Gradient Descent** (**max_iter, epsilon and lr**)\n",
        "* Follwing we perform an experiment to fix upon the stopping criteria, max no. of iterations and learning rate.\n",
        "* **Design** : Take off from last section from the result for lamda = 0 as L1_Loss and L2_Loss are same for lamda = 0.\n",
        "* Tweak learning rate, epsilon and max_iter for lamda as 1 to obtain the final values."
      ],
      "metadata": {
        "id": "aV_qbmpTx9aH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments for Gradient Descent for L1 Loss"
      ],
      "metadata": {
        "id": "plY5NgiVrtFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize w as w_init\n",
        "# from uniform distribution over [0,1) \n",
        "w_init = np.random.rand(x.shape[1]+1)"
      ],
      "metadata": {
        "id": "4Qazad9Cv_X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with learning rate and \n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 1, 1000, 1e-8, 0.17, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS6O68LIyrf2",
        "outputId": "9c06d925-a747-442b-dc76-0c3429dce878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  2.8315282379121705\n",
            "minimum loss =  20.911986809541116 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try for variety of learning rates\n",
        "lr_arr = [0.23, 0.21, 0.19, 0.17, 0.15, 0.1, 0.05, 0.01]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 1, 1000, 1e-8, lr, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MgcQhs6y5VG",
        "outputId": "9d315d4c-aca2-4deb-f06b-f4de5e153503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  1.092223092617715e+188\n",
            "minimum loss =  3.129956910080877e+188 \n",
            "\n",
            "count =  1000\n",
            "delta =  1.2294887468771121e+40\n",
            "minimum loss =  1.4703753543902869e+41 \n",
            "\n",
            "count =  1000\n",
            "delta =  4.449907428140264\n",
            "minimum loss =  117.56730490618553 \n",
            "\n",
            "count =  1000\n",
            "delta =  2.8315282379121705\n",
            "minimum loss =  20.911986809541116 \n",
            "\n",
            "count =  1000\n",
            "delta =  1.681793769097677\n",
            "minimum loss =  9.42286735904564 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.3528163922068419\n",
            "minimum loss =  5.909340322138258 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.15582292989512148\n",
            "minimum loss =  5.356285982004833 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.021277999152600202\n",
            "minimum loss =  5.017060879279802 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observing the trend in minimum losses above, it seems best to go with learning rate = 0.21 as it gives minimum loss. It is also observed that lowering the learning rates below 0.17 clearly improves performance.\n",
        "\n",
        "Let's hold onto that observation and explore it further if 0.21 doesn't perform well for lamda = 0 and 0.5"
      ],
      "metadata": {
        "id": "yabOwuexAECE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try lr = 0.21 for lamda = 0 and 0.5\n",
        "# lamda = 0\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0, 1000, 1e-8, 0.21, L1_Loss, L1_Gradient)\n",
        "# lamda = 0.5\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 1000, 1e-8, 0.21, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbDI0PyEBD5I",
        "outputId": "ba70bcfa-6c5d-4a4f-a38b-1a3804853b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  1.1735933409459498e+38\n",
            "minimum loss =  1.4035286853877655e+39 \n",
            "\n",
            "count =  1000\n",
            "delta =  3.679809918364251e+39\n",
            "minimum loss =  4.400773757829708e+40 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation : minimum loss acheived for lamda = 0 and 0.5 shoots off to very large values at this rate.\n",
        "\n",
        "Clearly, we need to get back to that thought and explore lower learning rates further.\n",
        "\n"
      ],
      "metadata": {
        "id": "_-KZcKO8BfCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try for lower learning rates\n",
        "lr_arr = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005]\n",
        "for lr in lr_arr:\n",
        "  Gradient_Descent_modified (x_train, t_train, w_init, 1, 1000, 1e-8, lr, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5h0Khx4CMYI",
        "outputId": "93a4dca8-8d3a-4c8e-822d-594d0cfdb69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  0.3528163922068419\n",
            "minimum loss =  5.909340322138258 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.15582292989512148\n",
            "minimum loss =  5.356285982004833 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.021277999152600202\n",
            "minimum loss =  5.017060879279802 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.009021724243903684\n",
            "minimum loss =  4.978974231234468 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.06830173710321219\n",
            "minimum loss =  22.79825710044705 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.22868564197472097\n",
            "minimum loss =  123.67259859213863 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate of 0.01 seems to be the best choice here. We could go for 0.005 but there is really only a slight improvement. This doesn't seem worth going for such a slow learning rate.\n",
        "\n",
        "Next for learning rate of 0.01, increase/decrease max_iter to see the effect on performance."
      ],
      "metadata": {
        "id": "Anuyj5TzC6o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max_iter = 5000\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 1, 5000, 1e-8, 0.01, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnrLE8goD1D_",
        "outputId": "189f55ec-c846-4185-e5a2-e02964e5628a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  5000\n",
            "delta =  0.014952461987906673\n",
            "minimum loss =  4.993727341141227 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max_iter = 500\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 1, 500, 1e-8, 0.01, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7odPEwiD_8B",
        "outputId": "ad00ebf4-35f9-4b96-c129-f719fb5daf17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  500\n",
            "delta =  0.031370487269527736\n",
            "minimum loss =  5.023748550786248 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For max_iter = 5000, there is not any significant improvement and for max_iter= 500, there isn't any significant depreciation in performance.\n",
        "\n",
        "So we finalize max_iter = 500 for now."
      ],
      "metadata": {
        "id": "pev_byR2ERzQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's validate our choice for lamda = 0 and 0.5"
      ],
      "metadata": {
        "id": "f37E52WeEmqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try max_iter=500, lr= 0.01 for lamda = 0 and 0.5\n",
        "# lamda = 0\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0, 500, 1e-8, 0.01, L1_Loss, L1_Gradient)\n",
        "# lamda = 0.5\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 500, 1e-8, 0.01, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YB1n8a0Ek5t",
        "outputId": "ffaf8027-76bc-479e-922d-3005fb7d8052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  500\n",
            "delta =  0.00019486020415282468\n",
            "minimum loss =  2.0069936384928164 \n",
            "\n",
            "count =  500\n",
            "delta =  0.001966806723394665\n",
            "minimum loss =  3.7786215339103486 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As compared to the values for minimum loss achieved before, 1.95 and 3.59 respectively, although there is slight depreciation, but again it isn't really very significant.\n",
        "\n",
        "But still to be on the safe side, let's increase the max_iter bound to 1000."
      ],
      "metadata": {
        "id": "NVw0W9BJFTfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try max_iter=500, lr= 0.01 for lamda = 0 and 0.5\n",
        "# lamda = 0\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)\n",
        "# lamda = 0.5\n",
        "Gradient_Descent_modified (x_train, t_train, w_init, 0.5, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B8s6ddiFs3X",
        "outputId": "48c0dee7-dbfe-485c-a51f-4cced6f24b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count =  1000\n",
            "delta =  3.0211561095283557e-05\n",
            "minimum loss =  1.9661075283750529 \n",
            "\n",
            "count =  1000\n",
            "delta =  0.005287759540400394\n",
            "minimum loss =  3.7634055300173266 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our final values of parameters of gradient descent are as follows."
      ],
      "metadata": {
        "id": "jzE4_0gHF9E2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final Gradient Descent Parameters**\n",
        "* Learning Rate (lr)  = 0.01\n",
        "* Maximum iterations (max_iter) = 1000\n",
        "* Epsilon =  1e-8"
      ],
      "metadata": {
        "id": "W5ijdyEhytHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hyperparameter Tuning***\n",
        "\n",
        "---\n",
        "\n",
        "* Plotting Validation RMSE vs 1/lamda\n",
        "* Intial range of 1/lamda : 10 to 1000, 100 values"
      ],
      "metadata": {
        "id": "uXqfJDQ1yuhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define initial range for 1/lamda from 1 to 1000\n",
        "# and observe the validation rmse plot.\n",
        "lamda_inv = np.linspace(1, 1000, 100)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  w_init = np.random.rand(x.shape[1]+1)\n",
        "  # run gradient descent and store resulting w in w_op (w optimal)\n",
        "  w_op = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, 1/l_inv, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)[0]\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "c6GTFwjGy64b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Train_RMSE)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ynW-iDIvy6wP",
        "outputId": "1554549d-f314-4e4d-ccef-841c1b8722bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DW6l3QBjy6nw",
        "outputId": "9bb4a972-a65f-4c20-8293-a89844b32462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On closely observing the validation rmse curve, it seems like the minima occurs somewhere close to the starting point of the range of 1/lamda plotted.\n",
        "\n",
        "Let's zoom in to that range on the validation rmse curve.\n",
        " Use lamda_inv range as 5 to 800."
      ],
      "metadata": {
        "id": "xC4L9HvRHPZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : this cell takes around 1m to execute\n",
        "\n",
        "lamda_inv = np.linspace(5, 800, 50)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  w_init = np.random.rand(x.shape[1]+1)\n",
        "  # run gradient descent and store resulting w in w_op (w optimal)\n",
        "  w_op = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, 1/l_inv, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)[0]\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  # Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "NGzekGWqy9ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uiAzI4chZPl5",
        "outputId": "c0e974a8-0d9d-4b68-d411-b262fb447e5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe a clear minima. Let's go ahead, calculate the same and store it for future reference."
      ],
      "metadata": {
        "id": "sKzAymV0LB8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv_min = lamda_inv[np.argmin(Val_RMSE)]\n",
        "val_rmse_min = np.min(Val_RMSE)\n",
        "print('1/lamda at minima = ', lamda_inv_min)\n",
        "print('Minimum Validation RMSE = ', val_rmse_min)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiZOX0tgLM_5",
        "outputId": "29eef3be-1231-4c36-bed2-d23137d8880e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/lamda at minima =  21.224489795918366\n",
            "Minimum Validation RMSE =  1.488102186382294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now although we have got a clear minima, just to be on the safe side, and ensure that it is indeed a global minima, let's observe the validation rmse curve for a very wide range of 1/lamda.\n",
        "\n",
        "Let's choose the range as 100 to 1e+8"
      ],
      "metadata": {
        "id": "3Aly0ineLVSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE : This Cell Takes around 1m 40s to execute\n",
        "\n",
        "lamda_inv = np.linspace(20, 1e+6, 100)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  w_init = np.random.rand(x.shape[1]+1)\n",
        "  # run gradient descent and store resulting w in w_op (w optimal)\n",
        "  w_op = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, 1/l_inv, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)[0]\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  # Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "bXNi1dwGJV7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "erlUgShNLlJZ",
        "outputId": "0ce0953b-b8fe-424a-962f-ed37a455c2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be clearly observed that the curve increases and saturates around a certain value and doesn't show any potential monotonically decreasing nature even for such a wide range of 1/lamda.\n",
        "\n",
        "Thus, the minima observed in the last run, is indeed a global minima."
      ],
      "metadata": {
        "id": "QFlwQFcYGrmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion**\n",
        "Thus best lambda for **L1 Loss** is approximately 1/21.224 = 0.047\n",
        "with validation rmse around 1.488"
      ],
      "metadata": {
        "id": "7n5JywFVIfY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save and print the final weight vector, validation rmse and nrmse for L1_Loss\n",
        "lamda_best_L1 = 1/lamda_inv_min\n",
        "w_best_L1 = Gradient_Descent(x_train, x_val, t_train, t_val, w_init, lamda_best_L1, 1000, 1e-8, 0.01, L1_Loss, L1_Gradient)[0]\n",
        "best_val_RMSE_L1 = np.sqrt(MSE_Loss(x_val, t_val, w_best_L1))\n",
        "best_val_NRMSE_L1 = NRMSE_Metric(x_val, t_val, w_best_L1)\n",
        "print('optimum w :\\n', w_best_L1)\n",
        "print('\\nValidation RMSE : ', best_val_RMSE_L1)\n",
        "print('Validation NRMSE : ', best_val_NRMSE_L1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPE7xC8tImKu",
        "outputId": "5948c5e4-69ce-45bf-b4b0-7df55833646a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimum w :\n",
            " [ 4.07122041e-01  4.83618127e-02  1.09909200e-01 -2.22591615e-02\n",
            "  1.71259343e+00  3.97673603e-01 -3.29580660e-01  2.66778791e-01\n",
            " -4.60139011e-01 -2.97238505e-02 -1.01781970e-01 -2.76571024e-01\n",
            " -4.26396135e-02  1.55575020e-01 -4.04807761e-04 -5.29611900e-04\n",
            " -3.99480144e-02 -1.09674155e-01 -1.60334430e-01  2.10100321e-01\n",
            "  1.10351000e-01  3.02150390e+01]\n",
            "\n",
            "Validation RMSE :  1.4920337107441677\n",
            "Validation NRMSE :  0.3965381413095892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pseudo-inverse Method for L2 Loss**"
      ],
      "metadata": {
        "id": "ABAtwAb4zfNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method gives the exact solution for minima of the L2 Loss function. Uptil now, we used gradient descent algorithm to estimate the minima of the loss function. \n",
        "\n"
      ],
      "metadata": {
        "id": "oqFwo5I_I7MT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning\n",
        "* Plotting Validation RMSE vs 1/lamda\n",
        "* Intial range of 1/lamda : 1 to 1000, 200 values"
      ],
      "metadata": {
        "id": "LKq8i1rIzqxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(1, 100, 50)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  # calculate optimum w using Pseudo_Inverse method\n",
        "  w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "_jsnd8ADzr9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Train_RMSE, color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "lI8nHLegzr6K",
        "outputId": "be6dca40-24ec-49cf-ed2a-dad08cd1ca40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "j9bC574pzr3i",
        "outputId": "1f253e3c-a2a4-4c1f-9a53-ef681a0c2948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, there is no hint of any minima in the curve above.\n",
        "\n",
        "Lets increase the range slightly, say 40 to 500."
      ],
      "metadata": {
        "id": "u3K8yLPmWFia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(40, 500, 100)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  # calculate optimum w using Pseudo_Inverse method\n",
        "  w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "kLvpyzp8Qw4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "m9X4Gy50Q403",
        "outputId": "085d7a49-852c-4fde-e770-a01383f51eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The changes in RMSE value are very insignificant. Let's validate this observation further by increasing the range as 400 to 5000."
      ],
      "metadata": {
        "id": "RH6vzdjTWX5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(400, 5000, 200)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  # calculate optimum w using Pseudo_Inverse method\n",
        "  w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "8Zrn3On_Q4oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "nmg_bCdwRBWR",
        "outputId": "47689c84-12ff-405c-92b8-c99ff489fb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just to be on safe side, lets now validate our observation that changes in validation rmse curve become highly insignificant for larger ranges, for a pretty wide range of 5000 to 5e+8."
      ],
      "metadata": {
        "id": "n7X0UgAPWt1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(5000, 5e+8, 400)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  # calculate optimum w using Pseudo_Inverse method\n",
        "  w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "XfW_gV8nROVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "8FUVF8X8RXVw",
        "outputId": "a269dea8-5f0f-48f1-9a1e-888f3551635c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Observation**\n",
        "Clearly as observed from the last 3 curves, the validation RMSE curve changes on the scale 1e-5, 1e-6 and 1e-7 as we keep increasing the range. These changes are insignificant.\n",
        "\n",
        "These small changes happen around RMSE = 1.5147."
      ],
      "metadata": {
        "id": "sYalUwW6Rdij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inference**\n",
        "\n",
        "Above implies that after a certain value of 1/lamda, variations in the validation rmse curve obtained by pseudo inverse method, are highly insignificant. \n",
        "\n",
        "Although being insignificant, there is still a decreasing nature of the curve.\n",
        "\n",
        "Most plausible reasons are that the overall training data was normalised before splitting, which might have made model already familiar with validation data or\n",
        "\n",
        "that the problem itself is too simple that even with increasing model complexity to very large values, **there is no noticeable effect of overfitting.**\n",
        "\n",
        "This nature not being observed in the previous sections could be attributed to the use of an approximate first order gradient descent algorithm for optimization."
      ],
      "metadata": {
        "id": "tsuadZQsS_DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Selecting the Best Lamda**\n",
        "The best value of lamda_inv now should be the least value at which the RMSE hits around 1.5147.\n",
        "\n",
        "Taking a look at the first curve, plausible candidates seem to be lie in the range 10-40. Let's plot the validation rmse for this range to make a better choice."
      ],
      "metadata": {
        "id": "hlEU3lWbYD8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamda_inv = np.linspace(10, 40, 400)\n",
        "Val_RMSE, Train_RMSE = [], []\n",
        "for l_inv in lamda_inv:\n",
        "  # calculate optimum w using Pseudo_Inverse method\n",
        "  w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "  # calc validation rmse and training rmse\n",
        "  Val_RMSE.append(np.sqrt(MSE_Loss(x_val, t_val, w_op)))\n",
        "  Train_RMSE.append(np.sqrt(MSE_Loss(x_train, t_train, w_op)))"
      ],
      "metadata": {
        "id": "IjC-xLd7YlGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lamda_inv, Val_RMSE, color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "V0n82BUMY4Ui",
        "outputId": "769d041e-be98-4823-cdcf-cd71084ebc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, it seems like we have a lot of choices for lamda. Inclining towards the least plausible choice of 1/lamda where the curve hits around 1.5147, Let's choose 1/lamda = 25 and validae the same"
      ],
      "metadata": {
        "id": "vTcVBtj3ZSvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate optimum w using Pseudo_Inverse method\n",
        "w_op = Pseudo_Inverse (x_train, t_train, 1/l_inv)\n",
        "# calc validation rmse and training rmse\n",
        "np.sqrt(MSE_Loss(x_val, t_val, w_op))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU5DjlFdaK3C",
        "outputId": "db182ac6-58f6-4437-a80d-24ae78abc641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5147753100334513"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, this works as expected. Lets fix this value for 1/lamda and save and print the final results."
      ],
      "metadata": {
        "id": "lX3MwpaVaT5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusion**\n",
        "\n",
        "A plausible choice for **Best Lamda** is 1/25 = 0.04 with validation RMSE approximately 1.51477"
      ],
      "metadata": {
        "id": "GZXxSkWqNfyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save and print the final weight vector, validation rmse and nrmse for Pseuod inverse method\n",
        "lamda_best_pseudo = 1/25\n",
        "w_best_pseudo = Pseudo_Inverse (x_train, t_train, lamda_best_pseudo)\n",
        "best_val_RMSE_pseudo = np.sqrt(MSE_Loss(x_val, t_val, w_best_pseudo))\n",
        "best_val_NRMSE_pseudo = NRMSE_Metric(x_val, t_val, w_best_pseudo)\n",
        "\n",
        "print('optimum w :\\n', w_best_pseudo)\n",
        "print('\\nValidation RMSE : ', best_val_RMSE_pseudo)\n",
        "print('Validation NRMSE : ', best_val_NRMSE_pseudo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbEDa5zuMG0z",
        "outputId": "b654b22e-eeee-459f-dac3-58928be97f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimum w :\n",
            " [ 4.42070681e-01  8.13953552e-02  5.12325497e-01 -1.48612276e-01\n",
            "  2.02737855e+00  1.37015493e-01 -3.69194512e-01  2.71529778e-01\n",
            " -4.01522703e-01 -1.21480830e-01 -1.57017882e-01 -3.06816782e-01\n",
            " -8.77656272e-02  1.97705773e-01 -3.20437568e-02  1.82600463e-02\n",
            " -7.65143537e-02 -1.26840047e-01 -2.28897495e-01  2.83805551e-01\n",
            "  1.05799945e-01  3.02274985e+01]\n",
            "\n",
            "Validation RMSE :  1.5148060468067912\n",
            "Validation NRMSE :  0.402590350284845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The Best Models so far**\n",
        "Following are thre best models tabulated along with the relevant details of loss functions and minimization technique."
      ],
      "metadata": {
        "id": "fQPjSd5jOOzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_models = {'Loss Function': ['L2', 'L1', 'L2'], 'Optimization method': ['Gradient Descent', 'Gradient Descent', 'Pseudo inverse (Analytical soln)'], \n",
        "                'Best Lamda':[lamda_best_L2, lamda_best_L1, lamda_best_pseudo ], 'Best Validation RMSE': [best_val_RMSE_L2, best_val_RMSE_L1, best_val_RMSE_pseudo]}\n",
        "df_best_models = pd.DataFrame(table_models)\n",
        "df_best_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Vopbv0zwOfJt",
        "outputId": "465a0580-3c4e-4465-88b2-b0ffc375cfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e6417ef3-a4f8-44b3-8e78-9d754bd0ee65\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss Function</th>\n",
              "      <th>Optimization method</th>\n",
              "      <th>Best Lamda</th>\n",
              "      <th>Best Validation RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>L2</td>\n",
              "      <td>Gradient Descent</td>\n",
              "      <td>0.090164</td>\n",
              "      <td>1.486896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>L1</td>\n",
              "      <td>Gradient Descent</td>\n",
              "      <td>0.047115</td>\n",
              "      <td>1.492034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>L2</td>\n",
              "      <td>Pseudo inverse (Analytical soln)</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>1.514806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6417ef3-a4f8-44b3-8e78-9d754bd0ee65')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6417ef3-a4f8-44b3-8e78-9d754bd0ee65 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6417ef3-a4f8-44b3-8e78-9d754bd0ee65');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Loss Function  ... Best Validation RMSE\n",
              "0            L2  ...             1.486896\n",
              "1            L1  ...             1.492034\n",
              "2            L2  ...             1.514806\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Best Model**\n",
        "\n",
        "Clearly, **\"L2 loss function\"** ***optimized by Gradient Descent*** gives the best validation RMSE (**1.486**)and thus the best model.\n",
        "\n",
        "Next we use the weight vector **\"w_best_L2\"** for prediction on test data."
      ],
      "metadata": {
        "id": "YxCxwTpFTkpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions on **Test Data**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HUrcFATJ0bku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read test data from the given link\n",
        "df_test = pd.read_csv(\"https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv\")"
      ],
      "metadata": {
        "id": "PhR2s5sAUMnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert test data to numpy array\n",
        "x_test = np.array(df_test)\n",
        "# normalise the test data\n",
        "x_test_norm = Normalize(x_test)"
      ],
      "metadata": {
        "id": "WRiPVMM5UjnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the test data predictions in Predictions_array\n",
        "Predictions_array = Prediction(x_test_norm, w_best_L2)"
      ],
      "metadata": {
        "id": "xwhqVl99cMLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the predictions array to a dataframe\n",
        "df_predictions = pd.DataFrame(Predictions_array, columns = ['Next_Tmax'])\n",
        "# write to csv file\n",
        "# df_predictions.to_csv('17d070041_18d070053_1.csv', index = False)"
      ],
      "metadata": {
        "id": "zUXaD_Ckdbzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "de7f27538e4ad9db84b046b2752843f1",
          "grade": false,
          "grade_id": "cell-8a98f665f9567cec",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "mw3AOqkvmK8I"
      },
      "source": [
        "#**... Part 2 ends.**\n",
        "\n",
        "1. Write the name or roll no.s of friends from outside your group with whom you discussed the assignment here (no penalty for mere discussion without copying code): \n",
        "2. Write the links of sources on the internet referred here (no penalty for mere consultation without copying code): "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Discussion with friends outside the group :\n",
        "\n",
        "* Shailee Suryawanshi : 17D070049"
      ],
      "metadata": {
        "id": "buP_h3CHfzH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References (Part 1)\n",
        "\n",
        "\n",
        "*   Joining two numpy arrays : https://www.geeksforgeeks.org/numpy-concatenate-function-python/\n",
        "*   Vector norm in numpy : https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
        "\n",
        "\n",
        "*   signum function in numpy : https://numpy.org/doc/stable/reference/generated/numpy.sign.html\n",
        "\n",
        "* Conceptual (Gradient descent) : https://towardsdatascience.com/gradient-descent-algorithm-a-deep-dive-cf04e8115f21#:~:text=Gradient%20descent%20(GD)%20is%20an,e.g.%20in%20a%20linear%20regression\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fc3t7HZ3BHgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References (Part 2)\n",
        "\n",
        "* Converting pandas DataFrame to numpy array : https://www.geeksforgeeks.org/pandas-dataframe-to_numpy-convert-dataframe-to-numpy-array/\n",
        "\n",
        "* Splitting dataset into Training and Validation : https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test\n",
        "\n",
        "*  Convert numpy array to csv file:  https://www.geeksforgeeks.org/convert-a-numpy-array-into-a-csv-file/\n"
      ],
      "metadata": {
        "id": "S5BXylI7CveM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "17d070041_18d070053_1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MDKB3K3AmK7-",
        "MqdqPlfEYavJ",
        "Okydr_hnq4eM",
        "2AZia-kuyFER",
        "plY5NgiVrtFT",
        "ABAtwAb4zfNN"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}